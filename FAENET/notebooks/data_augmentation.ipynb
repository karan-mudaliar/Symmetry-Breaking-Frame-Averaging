{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation for Slab Structures\n",
    "\n",
    "This notebook augments existing CSV data by flipping asymmetric slabs (those with `sym_vac=False`). For such slabs:\n",
    "1. Mirror the structure across the a/b plane\n",
    "2. Interchange the top and bottom workfunctions\n",
    "3. Mark the new entries as \"flipped\"\n",
    "\n",
    "This augmentation doubles the data for asymmetric slabs, which may help improve model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymatgen.core import Structure\n",
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Mirror Function\n",
    "\n",
    "This function mirrors a slab structure across the a/b plane (flipping it in the z-direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_slab(struc: Structure) -> Structure:\n",
    "    \"\"\"Mirror input structure across a/b plane\n",
    "    \n",
    "    Args:\n",
    "        struc: Input pymatgen Structure object\n",
    "        \n",
    "    Returns:\n",
    "        Mirrored structure\n",
    "    \"\"\"\n",
    "    structure: Structure = struc.copy()\n",
    "    species = structure.species_and_occu\n",
    "    frac_coords = structure.frac_coords\n",
    "    for f in frac_coords:\n",
    "        f[2] = 1 - f[2]\n",
    "    return Structure(structure.lattice, species, frac_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "First, we'll load the CSV data containing the slab structures and their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to the CSV file\n",
    "csv_path = \"../test_data/surface_prop_data_set_top_bottom.csv\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Loaded {len(df)} entries from {csv_path}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Check if the dataframe already contains a 'flipped' column\n",
    "has_flipped_column = 'flipped' in df.columns\n",
    "print(f\"Data already has 'flipped' column: {has_flipped_column}\")\n",
    "\n",
    "# Display sample data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Symmetric vs. Asymmetric Slabs\n",
    "\n",
    "Let's check how many slabs are symmetric (sym_vac=True) vs. asymmetric (sym_vac=False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which columns exist in the dataframe\n",
    "required_columns = ['slab', 'sym_vac', 'WF_top', 'WF_bottom']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "\n",
    "# Count symmetric vs. asymmetric slabs\n",
    "sym_count = df['sym_vac'].sum()\n",
    "asym_count = len(df) - sym_count\n",
    "\n",
    "print(f\"Symmetric slabs (sym_vac=True): {sym_count}\")\n",
    "print(f\"Asymmetric slabs (sym_vac=False): {asym_count}\")\n",
    "print(f\"Total slabs: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Data by Flipping Asymmetric Slabs\n",
    "\n",
    "Now we'll create new entries for all asymmetric slabs by:\n",
    "1. Flipping the structure\n",
    "2. Swapping top and bottom workfunctions\n",
    "3. Marking them as \"flipped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original dataframe\n",
    "df_original = df.copy()\n",
    "\n",
    "# If the flipped column already exists, we need to handle it differently\n",
    "if not has_flipped_column:\n",
    "    # Add flipped column to original data (empty for now)\n",
    "    df_original['flipped'] = \"\"\n",
    "    \n",
    "# Filter asymmetric slabs\n",
    "asym_slabs = df_original[df_original['sym_vac'] == False].copy()\n",
    "print(f\"Found {len(asym_slabs)} asymmetric slabs to flip\")\n",
    "\n",
    "# Create flipped versions\n",
    "flipped_rows = []\n",
    "\n",
    "for _, row in tqdm(asym_slabs.iterrows(), total=len(asym_slabs)):\n",
    "    # Create a copy of the row\n",
    "    flipped_row = row.copy()\n",
    "    \n",
    "    # Parse the structure from JSON string\n",
    "    structure_dict = json.loads(row['slab'])\n",
    "    structure = Structure.from_dict(structure_dict)\n",
    "    \n",
    "    # Flip the structure\n",
    "    flipped_structure = mirror_slab(structure)\n",
    "    \n",
    "    # Update the flipped row\n",
    "    flipped_row['slab'] = json.dumps(flipped_structure.as_dict())\n",
    "    \n",
    "    # Swap top and bottom workfunctions\n",
    "    flipped_row['WF_top'], flipped_row['WF_bottom'] = row['WF_bottom'], row['WF_top']\n",
    "    \n",
    "    # Mark as flipped\n",
    "    flipped_row['flipped'] = \"flipped\"\n",
    "    \n",
    "    # Update jid if needed\n",
    "    if 'jid' in row and row['jid']:\n",
    "        if has_flipped_column and row['flipped'] == \"flipped\":\n",
    "            # This was already a flipped structure, keep the existing jid\n",
    "            pass\n",
    "        else:\n",
    "            # Create a new jid by appending \"_flipped\"\n",
    "            flipped_row['jid'] = f\"{row['jid']}_flipped\"\n",
    "    \n",
    "    flipped_rows.append(flipped_row)\n",
    "\n",
    "# Create a dataframe from flipped rows\n",
    "df_flipped = pd.DataFrame(flipped_rows)\n",
    "print(f\"Created {len(df_flipped)} flipped entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Original and Flipped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine original and flipped data\n",
    "df_combined = pd.concat([df_original, df_flipped], ignore_index=True)\n",
    "print(f\"Combined dataset has {len(df_combined)} entries\")\n",
    "\n",
    "# Verify the counts\n",
    "normal_count = (df_combined['flipped'] == \"\").sum()\n",
    "flipped_count = (df_combined['flipped'] == \"flipped\").sum()\n",
    "print(f\"Normal entries: {normal_count}\")\n",
    "print(f\"Flipped entries: {flipped_count}\")\n",
    "\n",
    "# Display sample of combined data\n",
    "df_combined.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"../processed_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = os.path.join(output_dir, \"augmented_DFT_data.csv\")\n",
    "df_combined.to_csv(output_path, index=False)\n",
    "print(f\"Saved augmented dataset to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify a Sample Pair\n",
    "\n",
    "Let's visualize one original-flipped pair to verify our augmentation worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a sample original-flipped pair (using the first asymmetric slab)\n",
    "sample_original = df_original[df_original['sym_vac'] == False].iloc[0]\n",
    "if 'jid' in sample_original and sample_original['jid']:\n",
    "    sample_jid = sample_original['jid']\n",
    "    sample_flipped = df_flipped[df_flipped['jid'] == f\"{sample_jid}_flipped\"].iloc[0]\n",
    "else:\n",
    "    # If no jid, use the index position\n",
    "    sample_idx = df_original[df_original['sym_vac'] == False].index[0]\n",
    "    sample_flipped = df_flipped.iloc[0]\n",
    "\n",
    "# Print comparison\n",
    "print(\"=== Original Slab ===\")\n",
    "print(f\"WF_top: {sample_original['WF_top']:.4f}, WF_bottom: {sample_original['WF_bottom']:.4f}\")\n",
    "\n",
    "print(\"\\n=== Flipped Slab ===\")\n",
    "print(f\"WF_top: {sample_flipped['WF_top']:.4f}, WF_bottom: {sample_flipped['WF_bottom']:.4f}\")\n",
    "\n",
    "# Verify that top and bottom are swapped\n",
    "if abs(sample_original['WF_top'] - sample_flipped['WF_bottom']) < 1e-6 and \\\n",
    "   abs(sample_original['WF_bottom'] - sample_flipped['WF_top']) < 1e-6:\n",
    "    print(\"\\n✅ Verification successful: WF_top and WF_bottom were swapped correctly\")\n",
    "else:\n",
    "    print(\"\\n❌ Verification failed: WF_top and WF_bottom were not swapped correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Compatibility with FAENet DataLoader\n\nThe existing FAENet data loader is fully compatible with this augmented dataset. Here's how it works:\n\n1. The `EnhancedSlabDataset` class loads the CSV file with all columns, including the newly added \"flipped\" column.\n2. During training, only columns listed in `target_properties` (like \"WF_top\" and \"WF_bottom\") are used as model inputs/outputs.\n3. Other columns like \"flipped\" are ignored during model training but remain in the dataset.\n4. The \"flipped\" column serves as metadata indicating which entries are original vs. augmented.\n\nTo use this augmented dataset for training, simply point the data_path to the new CSV file:\n\n```bash\npython -m faenet.train --data_path=./processed_data/augmented_DFT_data.csv --structure_col=slab --target_properties=[WF_top,WF_bottom] --frame_averaging=3D\n```\n\n## Conclusion\n\nThe data augmentation is complete! We've:\n1. Identified all asymmetric slabs (sym_vac=False)\n2. Created flipped versions of these slabs\n3. Swapped their top and bottom workfunctions\n4. Marked them as \"flipped\" in a new column\n5. Saved the augmented dataset\n\nThis augmentation should help improve training by providing more data and enhancing the model's ability to learn the relationship between structure and properties.",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}